This project investigates an AI-Agent framework for automatic misinformation checking on social media platforms, with a focus on Reddit. The approach integrates a data pipeline for efficient content retrieval and employs Large Language Models (LLMs) for the reasoning task, specifically targeting misinformation through toxicity analysis. The findings indicate a negative correlation between toxicity scores derived from LLMs and Reddit post upvotes, suggesting that posts with higher toxicity, indicative of potential misinformation, receive fewer upvotes. This correlation underscores the potential of LLM-based methods in identifying and mitigating misinformation on social media

Please refer to CS505_Final_Project_LLM_Agent_for_Social_Media_Misinformation_Detection for the final report.
